{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\n\nX_train = train_data[['Theta_AF7','Theta_AF8','Theta_TP9','Theta_TP10']]\ny_train= train_data[['Choice']]\n\nX_valid = test_data[['Theta_AF7','Theta_AF8','Theta_TP9','Theta_TP10']]\ny_valid = test_data[['Choice']]\n\n\nX_train =np.asarray(X_train.astype(float))\ny_train = np.asarray(y_train.astype(float))\n\nXtest = np.asarray(X_valid.astype(float))\nytest = np.asarray(y_valid.astype(float))\n\n#print(X_train.shape),print(y_train.shape),print(X_train.shape)\n\n\nmodel = DecisionTreeClassifier()\n\n\nmodel.fit(X_train,y_train)\n\n\n\nacc= model.score(Xtest,ytest)*100\nprint(acc)\n\n#X= data[['RAW_AF7','RAW_AF8']]\n#X = pd.DataFrame(X)\n\n#y = data['Choice']\n#y= pd.DataFrame(y)\n\n#Xtrain, Xtest, ytrain, ytest = train_test_split(X_train,y_train,test_size = 0.2, shuffle=True)\n\n#print(\"Shape of Xtrain : \",Xtrain.shape)\n#print(\"Shape of Xtest: \",Xtest.shape)\n#print(\"Shape of ytrain: \",ytrain.shape)\n#print(\"Shape of ytest: \",ytest.shape)\n#print(\"\")\n\n#model_log = LogisticRegression(max_iter=5)\n\n#model_log.fit(Xtrain,ytrain)\n\n#acc= model_log.score(Xtest,ytest)*100\n\n#print(\"Accuracy = \",acc,\"%\")\n\n#result = model_log.predict(Xtest)\n\n#result = pd.DataFrame(result)\n#result['Actual Labels'] = y_valid\n#result\n\n\n# Calculating the accuracy from predicted values by the model and true values:\n\n#from sklearn.metrics import accuracy_score\n#accuracy = accuracy_score(result,ytest)\n#print(accuracy)\n\n#test_score=[]\n#train_score=[]\n#arr=5*(np.arange(10))\n#max iteration in logistic Regression for training and storing test and train score \n\n\n\n#ploting the Score\n''''import matplotlib.pyplot as plt\nplt.xlabel('iteraations ')\nplt.ylabel('Accuracy ')\nplt.title('Logistic Regression Acurracy Grafh')\nplt.plot(arr,train_score,label='traing accuracy')\nplt.plot(arr,test_score,label='testing accuracy')\nplt.legend(loc='upper left')'''\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\nX_train = train_data[['Theta_AF7','Theta_AF8','Theta_TP9','Theta_TP10']]\ny_train= train_data[['Choice']]\n\nX_valid = test_data[['Theta_AF7','Theta_AF8','Theta_TP9','Theta_TP10']]\ny_valid = test_data[['Choice']]\n\n#Converting as arrays\nX_train =np.asarray(X_train.astype(float))\ny_train = np.asarray(y_train.astype(float))\n\nX_test = np.asarray(X_valid.astype(float))\ny_test = np.asarray(y_valid.astype(float))\n\n#print(X_train.shape),print(y_train.shape),print(X_test.shape),print(y_test.shape)\n\nclassifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train,y_train)\n\nacc= classifier.score(X_test,y_test)*100\nprint(acc,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\nX_train = train_data[['Theta_AF7','Theta_AF8','Theta_TP9']]\ny_train= train_data['Choice']\n\nX_valid = test_data[['Theta_AF7','Theta_AF8','Theta_TP9']]\ny_valid = test_data['Choice']\n\n#Converting as arrays\n\nX_train =np.asarray(X_train.astype(float))\ny_train = np.asarray(y_train.astype(float))\n\nX_test = np.asarray(X_valid.astype(float))\ny_test = np.asarray(y_valid.astype(float))\n\nclf = svm.SVC(kernel='linear')\n\nclf.fit(X_train,y_train)\nacc= clf.score(X_test,y_test)*100\nprint(acc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegression \nimport warnings\nwarnings.filterwarnings('ignore')\n\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\nX_train = train_data[['RAW_AF7','RAW_AF8','RAW_TP9','RAW_TP10']]\ny_train= train_data[['Choice']]\n\nX_valid = test_data[['RAW_AF7','RAW_AF8','RAW_TP9','RAW_TP10']]\ny_valid = test_data[['Choice']]\n\n#Converting into arrays\n\nX_train =np.asarray(X_train.astype(float))\ny_train = np.asarray(y_train.astype(float))\n\nX_test = np.asarray(X_valid.astype(float))\ny_test = np.asarray(y_valid.astype(float))\n\n\n\n#regression = LogisticRegression(max_iter = 100)\n#regression.fit(X_train,y_train)\n#print(\"Train Accuracy:\",regression.score(X_train,y_train))\n#print(\"Test Accuracy:\",regression.score(X_test,y_test))\n\n\n\ntest_score=[]\ntrain_score=[]\narr=5*(np.arange(5))\n\n# max iteration in logistic Regression for training and storing test and train score\n\nfor i in arr:\n    log1 = svm.SVC()\n    log1.fit(X_train,y_train)\n    test_score.append(log1.score(X_test,y_test))\n    train_score.append(log1.score(X_train,y_train))\n\n#ploting the Score\nimport matplotlib.pyplot as plt\n\nplt.xlabel('iteraations ')\nplt.ylabel('Accuracy ')\nplt.title('Logistic Regression Acurracy Grafh')\nplt.plot(arr,train_score,label='traing accuracy')\nplt.plot(arr,test_score,label='testing accuracy')\nplt.legend(loc='upper left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(log1, Xtest, ytest)\nlog1.score(Xtest,ytest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neural Networks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras import models,layers\n\ndata = pd.read_csv('../input/eeg-subject-1/output.csv')\n\n\nX= data[['RAW_AF7','RAW_AF8']]\nX = pd.DataFrame(X)\n\ny = data['Choice']\ny= pd.DataFrame(y)\n\n\n#Splitting the data by using a function train_test_split from its library\n\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size = 0.2,shuffle = True)\n\n#checking the shape of splitted data\nX_train.shape,X_valid.shape,y_train.shape,y_valid.shape\n\n\n#Converting the training labels into categorical data, as the classes are 10 of these data\ny_train = to_categorical(y_train,2)\n\n#Converting the validation labels into categorical data, as the classes are 10 of these data\ny_valid = to_categorical(y_valid,2)\n\n\n\n#Creating the sequential model\nmnist_model_10 = models.Sequential()\n\n#Making the data vector by using flattening\nmnist_model_10.add(layers.Flatten())\n\n#ReLu function usage\nmnist_model_10.add(layers.Dense(2,activation='relu',input_shape=(21504,2))) \n\n#Softmax function usage for taking output as one\nmnist_model_10.add(layers.Dense(2,activation='softmax'))  \n\n#Using the adam optimizer\nmnist_model_10.compile(optimizer = 'adam', loss='categorical_crossentropy',metrics = ['acc'])\nmodel_history = mnist_model_10.fit(X_train,y_train,epochs=10, validation_data = (X_valid,y_valid));\nhist_dict = model_history.history\n\n\n#Storing the epochs as the length of the dictionary accuracy\nepochs = np.arange(len(hist_dict['acc']))\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title(\"Training and Validation Accuracy Graph\")\nplt.plot(epochs+1,hist_dict['acc'],label='Training Accuracy')\nplt.plot(epochs+1,hist_dict['val_acc'],label='Validation Accuracy')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using 25 products for training and 5 for testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport glob\nimport sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras import models,layers\n# first neural network with keras tutorial\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\nX_train = train_data[['Theta_TP9','Theta_AF7','Theta_AF8','Theta_TP10']]\ny_train= train_data['Choice']\n\nX_valid = test_data[['Theta_TP9','Theta_AF7','Theta_AF8','Theta_TP10']]\ny_valid = test_data['Choice']\n\nprint(Xtrain.shape)\n    \n\n\n\n\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=2, activation='relu'))\nmodel.add(Dense(4, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# fit the keras model on the dataset\nmodel.fit(X_train, y_train, epochs=5, batch_size=10)\n\n# evaluate the keras model\n_, accuracy = model.evaluate(X_train,y_train)\nprint('Accuracy: %.2f' % (accuracy*100))\n\n#predict_data = X_valid.iloc[0:5]\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\npath_train =  \"../input/train-test-subject1/Training_s1.csv\" # use your path\npath_test =   \"../input/train-test-subject1/Testing_s1.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\nX_train = train_data[['RAW_AF7','RAW_AF8']]\ny_train= train_data['Choice']\n\n\nX_test = test_data[['RAW_AF7','RAW_AF8']]\ny_test = test_data['Choice']\n\n\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(2,)),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n\n    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=15, batch_size=10)\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint('Test Accuracy:', test_acc)\nprint('Test Loss:', test_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Predicting the class"},{"metadata":{"trusted":true},"cell_type":"code","source":"a= np.array([[0.049869828,0.38199887,0.3522458,0.21735173]])\nprint(model.predict(a))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7 subjects - 25 products for train - 5 producs for test"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\npath_train =  \"../input/7-subjects-merged-25train-5test/Train_data.csv\" # use your path\npath_test =   \"../input/7-subjects-merged-25train-5test/Test_data.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\n\n\nX_train = train_data[['Theta_TP9','Theta_AF7','Theta_AF8','Theta_TP10']]\ny_train= train_data['Choice']\n\n\nX_test = test_data[['Theta_TP9','Theta_AF7','Theta_AF8','Theta_TP10']]\ny_test = test_data['Choice']\n\n\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(4,)),\n    keras.layers.Dense(16, activation=tf.nn.relu),\n\tkeras.layers.Dense(16, activation=tf.nn.relu),\n    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n])\n\nmodel.compile(optimizer='SGD',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=30, batch_size=1024)\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint('Test Accuracy:', test_acc)\nprint('Test Loss:', test_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries \nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n\npath_train =  \"../input/3-subjects137/train.csv\" # use your path\npath_test =   \"../input/3-subjects137/Test.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\n\nX_train = train_data[['Theta_AF7']]\ny_train= train_data[['Choice']]\n\n\nX_test = test_data[['RAW_AF7']]\ny_test = test_data['Choice']\n\n\nX_train = np.isnan(X_train)\n\n\nmodel = KNeighborsClassifier(n_neighbors =7)\n\n#Fitting the model to be trained\n\nmodel.fit(X_train,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape,X_test.shape, _test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nimport glob\n#import sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n#from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nimport scipy\nimport pywt\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import seaborn as sns\nfrom numpy import *\nfrom scipy.signal import *\nfrom numpy.fft import *\nfrom matplotlib import *\nfrom scipy import *\nfrom pylab import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pylab import *\nimport scipy.io\nimport scipy.signal\nimport scipy.fftpack\nfrom scipy.signal import butter, lfilter\nimport pywt\nfrom scipy.signal import savgol_filter\nimport numpy as np\nfrom hmmlearn import hmm\nfrom sklearn.linear_model import LogisticRegression\n\ndata = pd.read_csv('../input/subject-1-products-5/1.csv')\n\nX= data['RAW_AF7']\n\n\n\nfiltered = savgol_filter(X, 5, 2)\n\nfiltered = pd.DataFrame(filtered)\nfiltered.plot()\n\n\ncA, cD = pywt.dwt(X, 'db4')\n\ngamma_band = cD\ndata2= cA;\n\ncA, cD = pywt.dwt(data2, 'db4')\nbeta_band = cD;\ndata3=cA;\n\ncA, cD = pywt.dwt(data3, 'db4')\nalpha_band = cD;\ndata4=cA;\n\ncA, cD = pywt.dwt(data2, 'db4')\nTheta_band = cD;\nDelta_band = cA;\n\n\nplt.figure(1)\nplt.title(\"RAW Signal (AF7) \")\nplt.plot(X)\n\nplt.figure(2)\nplt.title(\"Filtered\")\nplt.plot(filtered)\n\nplt.figure(3)\n\nplt.subplot(5,1,1)\nplt.title(\"Gamma Band\")\nplt.plot(gamma_band)\nplt.show()\n\n\nplt.subplot(5,1,2)\nplt.title(\"beta Band\")\nplt.plot(beta_band)\nplt.show()\n\nplt.subplot(5,1,3)\nplt.title(\"Alpha Band\")\nplt.plot(alpha_band)\nplt.show()\n\nplt.subplot(5,1,4)\nplt.title(\"Theta Band\")\nplt.plot(Theta_band)\nplt.show()\n\nplt.subplot(5,1,5)\nplt.title(\"Gamma Band\")\nplt.plot(Delta_band)\nplt.show()\n\n\n\n#arr = pd.DataFrame(Theta_band)\n\n\n\nprint(filtered.shape), print(Theta_band.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X[0:200])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\npath1 = r\"../input/subject-1-products-5/1.csv\" # use your path\npath2 = r\"../input/subject-1-products-5/2.csv\" # use your path\npath3 = r\"../input/subject-1-products-5/3.csv\" # use your path\npath4 = r\"../input/subject-1-products-5/4.csv\" # use your path\n\n\n# Importing the data\n\n\ndata1 = pd.read_csv(path1)\ndata2 = pd.read_csv(path2)\ndata3 = pd.read_csv(path3)\ndata4 = pd.read_csv(path4)\n\n\ndt1 = data1[['RAW_AF7','RAW_AF8']]\ndt2 = data2[['RAW_AF7','RAW_AF8']]\ndt3 = data3[['RAW_AF7','RAW_AF8']]\ndt4 = data4[['RAW_AF7','RAW_AF8']]\n\n\n#dt1 = np.transpose(dt1)\n#dt2 = np.transpose(dt2)\n#dt1 = np.transpose(dt3)\n#dt2 = np.transpose(dt4)\n\narr = [[dt1,1],[dt2,0],[dt3,1],[dt4,0]]\n\n#arr = numpy.transpose(arr)\n\narr = pd.DataFrame(arr)\n\n\n\n\n\n\n#Xtrain, Xtest, ytrain, ytest = train_test_split(X,labels,test_size = 0.5, shuffle=True)\n\n#print(\"Shape of Xtrain : \",Xtrain.shape)\n#print(\"Shape of Xtest: \",Xtest.shape)\n#print(\"Shape of ytrain: \", ytrain.shape)\n#print(\"Shape of ytest: \",ytest.shape)\n#print(\"\")\n#labels\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the own decomposed features for Product # 01"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split \nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\npath_train =  \"../input/product01-all-bands-dwt-decomposed-features/P#01/Theta_bands_P1.csv\" # use your path\n\n\ntrain_data = pd.read_csv(path_train)\n\ndata_t,labels_t = train_data.loc[:,train_data.columns!='Labels'],train_data.Labels\n\n\nfrom sklearn.utils import shuffle\n\ndata_t =data_t.fillna(data_t.mean())\n\ndata,labels = shuffle(data_t,labels_t,random_state=9896)\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nXtrain, Xtest, ytrain, ytest = train_test_split(data,labels,test_size = 0.25, shuffle=True)\nXtrain.shape, Xtest.shape, ytrain.shape, ytest.shape\n\n","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"((525, 4), (175, 4), (525,), (175,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = DecisionTreeClassifier()\n\n\nmodel.fit(Xtrain,ytrain)\n\n\n\nacc= model.score(Xtest,ytest)*100\nprint(acc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy = model.score(Xtest,ytest)\ntrain_accuracy = model.score(Xtrain,ytrain)\n\nprint(\"Using Decision Tree Classifier \\n\")\n\nprint(\" Train Accuracy \", train_accuracy) \nprint(\" Test Accuracy \", test_accuracy) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclassifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(Xtrain,ytrain)\n\nacc= classifier.score(Xtest,ytest)*100\nprint(acc,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy = classifier.score(Xtest,ytest)\ntrain_accuracy = classifier.score(Xtrain,ytrain)\n\nprint(\"Using K-NN Classifier \\n\")\nprint(\"Train Accuracy \", train_accuracy) \nprint(\"Test Accuracy \", test_accuracy) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(Xtrain, ytrain)\n\n#Predict the response for test dataset\ny_pred = clf.predict(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy = clf.score(Xtest,ytest)\ntrain_accuracy = clf.score(Xtrain,ytrain)\n\nprint(\"Using SVM Classifier \\n\")\nprint(\" Train Accuracy \", train_accuracy) \nprint(\" Test Accuracy \", test_accuracy) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Area Under Curve"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from __future__ import print_function\n\nimport numpy as np\nfrom scipy.integrate import simps\nfrom numpy import trapz\n\n\n# The y values.  A numpy array is used here,\n# but a python list could also be used.\ny = Xtrain\n\n# Compute the area using the composite trapezoidal rule.\narea = trapz(y, dx=5)\nprint(\"area =\", area)\n\n# Compute the area using the composite Simpson's rule.\narea = simps(y, dx=5)\nprint(\"area =\", area)","execution_count":55,"outputs":[{"output_type":"stream","text":"area = [ 2.35733212e+01 -9.00573257e+01 -5.74591378e+01  9.05111477e-01\n -5.72516195e+01 -4.79585957e+01 -8.86949693e+01  6.38369625e+01\n -2.12872257e+01  2.03444199e+02 -2.49375876e+02 -9.53076894e+01\n -1.19955478e+02  6.19483293e+01  5.87382274e+01 -3.75744252e+01\n -7.79847330e+01 -6.75691383e+00 -5.61915582e+01  4.36622838e+01\n  1.22922482e+02 -3.41246901e+01  8.77391626e+01  1.64645900e+02\n  2.25463134e+02  1.82682511e+02  7.59831579e+01 -2.17692457e+01\n  3.91163399e+01  2.07387804e+02 -1.45643928e+02 -2.21024601e+02\n  9.10397381e+00 -3.15447573e+01 -9.22131866e+01 -7.72183817e+01\n  2.64322156e+02  2.28240978e-03 -4.74271003e+01  8.11760627e+00\n  7.92318581e+00  1.15815443e+02 -1.79572194e+02  5.42468016e+01\n  8.97270430e+01  2.88698908e+01  3.71353853e+01 -3.45982256e+01\n  5.93627576e+01 -1.21978591e+02  8.66236347e+01 -5.67762134e+01\n -4.60742352e+01  1.00867079e+00 -3.63580164e+00 -8.41494014e+01\n  2.02966205e+02 -2.34303151e+01  1.46935100e+00 -5.95900097e+00\n -2.73076084e+02 -7.31340742e+01 -1.85138611e+01 -5.38791131e+01\n  3.60793349e+01  1.05795623e+02  3.55387029e+01  7.73440711e+00\n -1.46903160e+02 -2.12578949e+01  1.05375540e+01 -3.04056914e+01\n -7.10863674e+01 -4.25751026e+00  4.88207337e+01  5.25037581e+00\n -1.92865531e+02  1.35521035e+02 -3.14304600e+02  2.34280208e+00\n  2.60476581e+01 -3.14927550e+01 -1.30812600e+02 -1.20958939e+02\n -1.05782147e+01 -2.69140072e+02 -6.53476800e+01 -4.35671120e+00\n  1.23270046e+02  6.60786326e+01  6.70962989e+01  6.35132637e+01\n  1.76031200e+02 -2.78719724e+00 -3.12888181e+01 -5.08134650e+01\n  1.11563909e+02  3.74990382e+01 -6.98739832e+01 -5.95173713e+01\n  3.16061501e+02  4.99324447e+01 -5.35236642e+00 -2.54974144e+01\n  9.25142097e+01  6.36093395e+01  5.08860237e+01  1.00000286e+01\n -9.24959811e+01 -7.14044446e+01 -6.34575933e+01 -9.31432304e+01\n -7.79119386e+01  3.28892564e+00  8.04528224e+01  5.90371835e+01\n  1.13802928e+02  2.89306112e+01  1.01745576e+02  1.31111609e+01\n -1.76702846e+01 -5.37983253e+01  1.66426812e+01  7.51021218e+01\n  2.84199400e+01 -1.82787156e+01 -2.77801997e+01  4.58629224e+01\n -6.49194058e+01  5.65622906e+01  8.54341081e+01 -1.48243647e+01\n  2.21159641e+01 -5.41532603e+01  8.98181907e+00  1.16651948e+02\n -1.26964816e+01  3.99973459e+01  6.67054103e+01 -3.22347376e+01\n  4.58452115e+01 -1.27518946e+02  7.33172396e+01  9.82067131e+01\n  1.21686722e+02  2.53264474e+00  2.65732731e+01 -1.16985834e+02\n -2.21437200e+01 -9.15953044e+01  3.29133690e+01 -1.35030462e+02\n -1.08056802e+01  5.00615546e+01  5.40507668e+01  1.16479675e+01\n -9.14945107e+01 -1.13683977e+02 -2.09234567e+02 -1.92845229e+00\n  3.77248256e+01 -2.15541493e+02  2.35548382e+01 -1.01666535e+01\n -1.96035482e+02 -9.69270039e+01  5.14543003e+01  3.71348852e-01\n  1.26872207e+02  1.91344579e+00  7.20723080e+01 -2.59855187e+02\n -3.27730783e+01 -2.30519983e+01 -1.40558624e+02  1.82178857e+01\n -9.28551062e+00  5.75748140e+01 -5.12541226e+01 -1.39219580e+01\n  8.86070519e+01 -5.17343471e+01  1.09683268e+02 -5.34734360e+01\n -2.25621458e+01  1.37948585e+02 -1.61674508e+01 -8.12169032e+01\n  4.61053491e+01 -4.87687753e+01 -2.55228094e+01  1.37060367e+01\n -1.24952237e+02  3.59302684e+01  7.79213068e+01 -3.64875287e+01\n  1.55338751e+02 -2.87883525e+01 -6.12981100e+00 -1.88684193e+02\n -3.90382557e+01  1.02121104e+01  4.41990286e+01 -5.57145945e+00\n  1.23861493e+02  1.23369610e+01  1.60507290e+02  1.70412486e+01\n  6.15236140e+00 -1.84375016e+02  2.57125181e+01  1.41488410e+02\n -2.52311976e+02 -8.04697328e+00  2.29281673e+01 -1.20424602e+01\n  4.37237525e+00 -1.66501444e+01  2.73161984e+01 -2.74117805e+02\n -6.15895617e+01 -7.51708304e+01 -5.05521362e+01  6.40635754e+01\n -1.71988204e+02  2.02385329e+01 -1.05476420e+01  9.75287869e+00\n -2.21792574e+02  1.20873825e+01 -1.64005478e+02  2.60326490e+01\n -2.07914752e+00  1.33940948e+02 -9.38153655e+01  4.74753462e+00\n  6.62108559e+01  1.47386759e+02 -3.31241120e+01  3.87654719e+01\n  2.16002130e+01 -1.27449410e+01  5.19208029e+01 -1.44313606e+01\n  6.34537977e+00 -1.19973798e+02  4.22287703e+00  6.65174496e+01\n -1.21142495e+01 -3.21299280e+01 -1.76854590e+02  1.23911288e+02\n -2.58498557e+02 -3.03363244e+01  1.68534779e+01  2.38648602e+01\n  9.78807256e+01  1.79041195e+02 -1.60439374e+01  2.59281373e+01\n -6.06786031e+00 -5.65081791e+01  2.23365870e+01  1.14857418e+02\n -1.06715662e+02  3.43670184e+01 -2.28001746e+02 -5.28973999e+01\n -1.69328828e+02  5.70351843e+01  7.02161645e+01  7.34229432e+01\n  6.56087025e+01  6.66314873e+01 -8.70113307e+01  4.79357126e-01\n  2.18694246e+01 -1.20720953e+02  2.89273804e+01  2.65725805e+01\n  1.45740065e+02  5.84571593e+00  7.96586806e+01 -1.63560238e+02\n -9.03448246e+01 -8.49894684e+01 -1.89940440e+02  1.48430459e+02\n -7.13120807e+01 -9.66156160e+01  8.00149944e+02 -1.78887740e+02\n  3.44273812e+00  4.28943726e+01  3.77285434e+01 -3.29427114e+01\n -1.10165665e+02  2.15203596e+01  2.62541094e+01 -2.80841162e+01\n -1.46971844e+02  1.38682376e+01  1.57845754e+02 -9.57922396e+00\n -1.06321478e+01  9.04908144e+01  5.65460515e+01  7.88771466e+01\n  2.08179709e+01  7.13083167e+01  1.75408544e+02  6.64460255e+01\n -8.37294265e+01 -4.46539159e+01  5.34846342e+01  2.05561579e+02\n  4.36926847e+01 -8.90377573e+01  9.26169441e+01 -1.09116756e+01\n -2.84330358e+01 -7.56683127e+01 -2.63798390e+01  2.28735041e+01\n  1.67763754e+01  7.54235376e+01  2.76763057e+01  2.60438604e+01\n  9.93132124e+00 -1.98903582e+02 -2.16829107e+02  2.27473176e+01\n  4.19699854e+02 -9.49037114e+01  9.26008382e+01 -1.99203758e+02\n -1.57083268e+02 -2.40646521e+01 -1.00599326e+02 -5.19589388e+01\n  1.73685557e+02 -2.05955888e+02  6.18008758e+01  2.96760476e+02\n -9.88333671e-01  5.73521793e+01 -1.54382552e+01 -2.92708484e+02\n  1.09812868e+02 -4.48426252e+01 -2.82152002e+02  1.88918719e+02\n  2.35115955e+01  5.67682036e+01 -8.30817082e+01 -9.29863959e+00\n  5.87068586e+01  2.53689467e+01  1.32691022e+02  2.83253835e+00\n  1.83321006e+02  4.26396036e+01  4.56850309e+01 -1.36385492e+01\n  1.11336030e+02  4.34354179e+01 -2.06477748e+01 -1.40574628e+02\n -8.32539486e+01  1.36538302e+01  1.04314415e+02 -1.60977737e+02\n  5.83618731e+01  8.04710792e+01 -4.17250330e+01 -1.31653561e+02\n  1.68480803e+02 -1.71900886e+00 -9.58227105e+01 -1.41614335e+02\n  4.00053315e+01  1.21207798e+02  2.55818014e+01 -6.75991986e+01\n  6.68650055e+01  6.69763782e+01 -5.64149157e-01 -8.94496584e+01\n  1.27605078e+01 -1.06498031e+01 -1.33867034e+01 -1.31506052e+02\n -8.05817376e+01  6.62599870e+01 -3.01483372e+01 -3.43743844e+01\n -3.87453891e+01  9.51951530e+01 -8.69361577e+01  4.56384152e+01\n  7.24160173e+01 -2.49458856e+02 -2.65652459e+01 -6.99164177e+01\n -9.65224207e+01 -1.02765185e+02 -7.00968629e+01 -4.08360057e+02\n  1.79516705e+01  1.07888019e+01 -1.37736871e+02 -1.61724954e+02\n -4.11884395e+01  2.71871887e+01  6.10886974e+01  1.63886404e+02\n -1.48399951e+02 -1.28066156e+02  3.33433042e+01 -4.26215551e+01\n  8.16074921e+01  1.27385494e+02  7.63370485e+01  6.04809856e+01\n -1.69598478e+02 -9.10003557e+01 -1.47329725e+02 -2.17207050e+00\n  3.12342984e+01  1.46261887e+02  1.29013015e+02 -6.85413872e+01\n -5.37393495e+00 -7.87895587e+00  1.45820823e+01  5.54823881e+00\n  6.49751831e+01 -3.66425462e+01 -4.24638386e+00 -5.44729634e+01\n  2.32576173e+02  6.55887093e+01 -5.10441562e+01 -8.55714383e+01\n -2.83639958e+01 -1.50243528e+02  3.36325726e+01 -3.67966916e+01\n  5.29155357e+01  6.97932060e+01  7.69977370e+01  2.60189129e+01\n -9.18623621e+00  2.79731404e+01 -5.07265343e+01 -1.19252491e+01\n -3.21066283e+01 -3.10463868e+01  2.26077388e+02  1.62548152e+02\n -1.36976271e+02 -6.03370381e+01  9.95522509e+01  4.29103111e+01\n  1.46016656e+02  2.72515437e+01 -6.07212044e+00  2.11574133e+01\n -3.80882836e-01 -5.10945370e+01 -1.63220940e+01 -3.22073459e+01\n -1.81107468e+02  3.65426706e+00  1.10792936e+02 -2.22609342e+02\n  8.77755466e+01 -3.61646800e+01 -4.71951539e+01  6.76076656e+00\n -2.67036261e+02 -2.23570526e+01  3.11418244e+01 -4.70217767e+01\n  1.27329157e+02 -7.03837761e+01  9.17998419e+01 -2.45381499e+01\n -3.37741843e+01 -1.20973494e+02  8.53770368e+01  1.72825366e+02\n  7.55441705e+01 -1.04593119e+02  5.28775624e+01  2.50754823e+00\n -1.50304829e+02  1.25648835e+01  1.29379801e+02  1.48712684e+02\n  1.35936897e+02  1.62116611e+02 -1.22283638e+02 -2.88492218e+01\n -4.64202797e+01  1.44106204e+01  1.28280984e+02 -3.65280240e+01\n  5.07046429e+01 -2.03289523e+01  1.08978003e+02  1.61823156e+01\n  1.10888994e+01  5.41336792e+01  1.50032813e+00 -1.17305157e+02\n  7.45166001e+01  1.35200103e+01 -2.90839918e+00  2.07501060e+01\n  1.66387831e+01 -9.46663175e+01  1.30456435e+02 -5.97595653e+01\n  7.15867422e+01]\narea = [ 2.61744810e+01 -8.57806514e+01 -6.29506835e+01 -1.38929128e+01\n -6.17661017e+01 -4.59327718e+01 -8.19255920e+01  5.70584473e+01\n -2.34283094e+01  2.12878197e+02 -2.53211784e+02 -9.54000558e+01\n -1.22068841e+02  5.35151053e+01  5.16578710e+01 -3.33180160e+01\n -8.27640056e+01 -1.47291634e+01 -5.89739602e+01  4.11698547e+01\n  1.27894284e+02 -3.86330152e+01  8.48091126e+01  1.77508629e+02\n  2.35593897e+02  1.86498884e+02  7.49253857e+01 -1.91532323e+01\n  3.90177569e+01  2.19557362e+02 -1.45731885e+02 -2.15941157e+02\n  6.86734093e+00 -3.68201511e+01 -1.02137477e+02 -7.43194491e+01\n  2.77495223e+02  2.51992054e+00 -5.60914708e+01 -1.45284977e+00\n  1.28017072e+01  1.16790156e+02 -1.84164485e+02  5.82889985e+01\n  8.98398044e+01  2.90159665e+01  3.83013564e+01 -3.61780029e+01\n  5.65407208e+01 -1.18969948e+02  8.86059959e+01 -6.45409962e+01\n -4.68581410e+01  2.10685238e+00  1.52282140e+00 -8.64234467e+01\n  2.12701567e+02 -1.72644571e+01  5.45323396e-01 -1.44521300e+01\n -2.95679528e+02 -7.64738986e+01 -1.96424885e+01 -5.01099448e+01\n  4.05370486e+01  1.05054196e+02  3.02431094e+01  1.09724829e+01\n -1.60482698e+02 -1.93598444e+01  1.06415531e+01 -2.46319228e+01\n -6.68511823e+01 -5.69627036e+00  5.49274031e+01 -6.08990037e+00\n -1.89827215e+02  1.34089263e+02 -2.53658085e+02  5.45954687e+00\n  2.00536734e+01 -2.47204050e+01 -1.38559295e+02 -1.12213329e+02\n -5.21204338e+00 -2.69756005e+02 -7.44854067e+01 -1.08621156e+01\n  1.24341460e+02  6.56597850e+01  7.23467778e+01  6.46787537e+01\n  1.89923710e+02 -5.34292032e+00 -2.00328529e+01 -4.15248662e+01\n  1.19395255e+02  3.72966337e+01 -7.19393553e+01 -5.88320644e+01\n  3.20474143e+02  4.26691777e+01  1.61628452e+01 -2.30831456e+01\n  8.67160070e+01  6.80352056e+01  5.50529382e+01  1.44866693e+01\n -8.35808590e+01 -6.96864563e+01 -6.90289552e+01 -9.98904005e+01\n -7.36771730e+01  5.89477306e+00  7.89820177e+01  5.83964478e+01\n  1.07215619e+02  2.03785936e+01  9.84542083e+01  1.85558332e+01\n -1.57188454e+01 -5.11557293e+01  1.20895775e+01  8.02121809e+01\n  3.26990149e+01 -2.46612829e+01 -2.45144300e+01  6.08324145e+01\n -6.08210690e+01  5.81956222e+01  8.84902853e+01 -2.50286982e+01\n  2.32078462e+01 -5.28849968e+01  1.32945526e+01  1.30867282e+02\n -8.21572502e-01  4.79416582e+01  6.25006193e+01 -4.12449253e+01\n  4.03596306e+01 -1.21228096e+02  6.75907897e+01  9.43893724e+01\n  1.19146545e+02  1.36222030e+01  2.35742470e+01 -1.10198474e+02\n -1.83815310e+01 -1.00091253e+02  3.73074228e+01 -1.49635852e+02\n -1.25978036e+01  4.76113263e+01  5.71120413e+01  8.78819276e+00\n -8.23536750e+01 -1.25676366e+02 -2.24794092e+02 -1.79431143e+00\n  3.97744482e+01 -2.14321246e+02  2.90788004e+01 -9.51385932e+00\n -2.02480218e+02 -9.51830998e+01  4.75444323e+01  2.61120544e+00\n  1.42982423e+02  3.29864576e+00  6.15829998e+01 -2.56587028e+02\n -3.70269851e+01 -1.85765862e+01 -1.47096467e+02  2.25256276e+01\n -9.19795315e+00  4.65028855e+01 -5.23092758e+01 -1.74430350e+01\n  1.06340218e+02 -5.73126683e+01  1.18556970e+02 -4.89277191e+01\n -2.89039331e+01  1.42961626e+02 -1.16881223e+01 -7.96568580e+01\n  3.14019639e+01 -4.95758683e+01 -2.33891048e+01  2.23571572e+01\n -1.23152503e+02  3.64763598e+01  8.99530037e+01 -3.24076547e+01\n  1.63876333e+02 -2.96946934e+01 -1.42340192e+01 -1.77851797e+02\n -4.30572871e+01  2.02479609e+01  3.99903362e+01 -2.81313258e+00\n  1.44195127e+02  1.20698352e+01  1.54656955e+02  7.50324001e+00\n  1.57836077e+01 -1.84430915e+02  3.75970917e+01  1.41207368e+02\n -2.52137044e+02 -1.40110702e+01  3.23743569e+01 -1.09483537e+01\n  7.13387962e+00 -5.35957661e+00  2.97389486e+01 -2.73097033e+02\n -6.09357216e+01 -8.15047234e+01 -5.57655638e+01  6.04896402e+01\n -1.45911167e+02  2.16822558e+01 -1.21575686e+01  2.27201865e+01\n -2.12680472e+02  6.83288945e+00 -1.83124886e+02  4.11313948e+01\n -4.53124973e+00  1.41581272e+02 -9.68001566e+01  1.97932152e+00\n  5.85734145e+01  1.47829772e+02 -4.06708488e+01  4.52318615e+01\n  1.42220450e+01 -5.78969354e+00  5.12061265e+01 -2.55362009e+01\n -1.18613423e+00 -1.18007736e+02 -2.09197510e+00  6.40315824e+01\n -5.26999053e+00 -3.86600437e+01 -1.92096322e+02  1.22947087e+02\n -2.70899860e+02 -3.28558314e+01  1.30111440e+01  2.27128942e+01\n  9.55204007e+01  1.83427270e+02 -1.69281166e+01  2.20950930e+01\n -1.30300384e+01 -5.75381162e+01  2.22172390e+01  1.25146905e+02\n -1.02483726e+02  3.97492755e+01 -2.38125508e+02 -6.19649523e+01\n -1.67332621e+02  6.68347992e+01  7.18342649e+01  7.49308540e+01\n  6.93760797e+01  6.30254051e+01 -8.41226394e+01 -2.72205224e+00\n  3.10659557e+01 -1.32954599e+02  3.42622914e+01  2.77223260e+01\n  1.38801674e+02  1.18127720e+00  7.63095222e+01 -1.76506018e+02\n -1.09352712e+02 -8.69189921e+01 -2.06687416e+02  1.56978999e+02\n -6.94097133e+01 -9.13958549e+01  7.49487180e+02 -1.77615797e+02\n  7.68703149e+00  5.31588822e+01  3.57042104e+01 -6.44620725e+00\n -1.03577488e+02  1.51424742e+01  3.01868577e+01 -2.64501611e+01\n -1.49559758e+02  9.28604311e+00  1.54365256e+02 -8.71276445e+00\n -2.02334048e+01  9.19237674e+01  5.47701121e+01  7.81238829e+01\n  2.41292972e+01  6.42539961e+01  1.91359535e+02  7.11546831e+01\n -5.68707869e+01 -4.81863824e+01  4.39561311e+01  2.05292599e+02\n  3.95097115e+01 -8.92003098e+01  9.18078665e+01 -1.08744630e+01\n -2.86750400e+01 -8.44390696e+01 -2.97217231e+01  3.42026666e+01\n  2.05574343e+01  7.65184437e+01  2.57759564e+01  3.04688080e+01\n  1.47472261e+01 -1.75936428e+02 -2.28188890e+02  2.94839430e+01\n  4.21675670e+02 -9.54672293e+01  9.56638367e+01 -1.91859344e+02\n -1.55560110e+02 -2.12699803e+01 -1.07047363e+02 -5.25316436e+01\n  1.71292337e+02 -2.15794676e+02  6.54742557e+01  3.12338498e+02\n -3.27582255e+00  6.56395952e+01 -1.35153868e+01 -2.86200348e+02\n  1.10248744e+02 -4.12081041e+01 -2.83495098e+02  1.93267583e+02\n  2.92824197e+01  5.28265731e+01 -9.29579926e+01 -1.08895704e+01\n  5.42254319e+01  1.91233888e+01  1.37761894e+02  1.32620354e+00\n  1.79669577e+02  4.34954455e+01  4.15856511e+01 -9.24204548e+00\n  9.92624095e+01  4.06156751e+01 -2.84585490e+01 -1.53827826e+02\n -8.73017234e+01  1.31192426e+01  1.05162209e+02 -1.68851558e+02\n  5.71015171e+01  8.23343080e+01 -3.21946394e+01 -1.44134237e+02\n  1.81123646e+02 -2.04969573e+01 -9.04989484e+01 -1.41933220e+02\n  4.09562751e+01  1.26223600e+02  3.61861154e+01 -6.76910479e+01\n  5.70965494e+01  7.38517201e+01 -7.65306517e+00 -9.47121622e+01\n  5.09011217e+00 -1.21565717e+01 -1.20824904e+01 -1.24719156e+02\n -7.17379651e+01  7.38021116e+01 -2.76399980e+01 -3.48152566e+01\n -2.92197641e+01  8.26043842e+01 -8.71275327e+01  4.63163856e+01\n  7.02527740e+01 -2.60050409e+02 -2.70120214e+01 -7.54574137e+01\n -9.66216630e+01 -8.30696785e+01 -8.06587678e+01 -4.06626832e+02\n  2.04106074e+01  5.16802178e+00 -1.46600265e+02 -1.65782892e+02\n -3.97556150e+01  3.68086844e+01  5.85162620e+01  1.60155676e+02\n -1.54432441e+02 -1.30674262e+02  3.08131459e+01 -3.90579529e+01\n  9.22181185e+01  1.29380743e+02  7.27732614e+01  6.62470062e+01\n -1.71441966e+02 -8.31944738e+01 -1.46062660e+02 -3.88914687e+00\n  2.41651066e+01  1.15381234e+02  1.35805693e+02 -6.82981317e+01\n  2.27334812e+00  5.13794118e-01  8.49429714e+00  2.22314728e+01\n  7.04962199e+01 -4.43225616e+01 -7.95390854e+00 -4.00177090e+01\n  2.49090816e+02  5.80630926e+01 -4.74633728e+01 -8.46879368e+01\n -2.25448012e+01 -1.52074050e+02  3.19333693e+01 -3.56726610e+01\n  5.34765108e+01  6.91252621e+01  7.59552706e+01  3.26001170e+01\n -2.26159039e+00  3.14866327e+01 -5.17443995e+01 -1.76245590e+01\n -3.96943995e+01 -2.87646887e+01  2.20311016e+02  1.67910085e+02\n -1.36502749e+02 -6.37441492e+01  1.02491242e+02  4.84782986e+01\n  1.43651479e+02  2.24342751e+01  1.01436760e+01  2.93075391e+01\n  3.48327791e+00 -4.93783233e+01 -1.73301397e+01 -3.42061198e+01\n -1.96582429e+02  8.41156391e+00  1.01924893e+02 -2.03194487e+02\n  9.96841954e+01 -4.12873486e+01 -3.66502894e+01  6.31604878e+00\n -2.77867599e+02 -2.36947649e+01  3.29847943e+01 -4.40993889e+01\n  1.40927176e+02 -7.14117058e+01  1.01817406e+02 -1.99988315e+01\n -3.43996631e+01 -1.23480270e+02  9.23746086e+01  1.40930323e+02\n  7.71795274e+01 -1.11153689e+02  5.40257981e+01  7.69790781e+00\n -1.51495976e+02  1.29174684e+01  1.32025010e+02  1.41376859e+02\n  1.34589092e+02  1.56666197e+02 -1.22668404e+02 -3.25100647e+01\n -5.17952628e+01  1.62837826e+01  1.25910626e+02 -3.59426487e+01\n  5.91419158e+01 -1.74096450e+01  1.15811798e+02  1.59855003e+01\n  4.42422629e+00  6.16670991e+01  3.48163609e+00 -1.17564867e+02\n  6.23814559e+01  1.56549922e+01 -7.21403833e+00  2.00229877e+01\n  1.13153651e+01 -1.02137434e+02  1.33409094e+02 -5.07471816e+01\n  7.12222444e+01]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_AF7 = Xtrain['Theta_AF7']","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import auc\n\n\nxx = np.arange(0,525,1)\nyy = theta_AF7\n\nprint('computed AUC using sklearn.metrics.auc: {}'.format(auc(xx,yy)))\n","execution_count":64,"outputs":[{"output_type":"stream","text":"computed AUC using sklearn.metrics.auc: -397.6490409414104\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_AF8 = Xtrain['Theta_AF8']","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import auc\n\n\nxx = np.arange(0,525,1)\nyy = theta_AF8\n\nprint('computed AUC using sklearn.metrics.auc: {}'.format(auc(xx,yy)))\n","execution_count":66,"outputs":[{"output_type":"stream","text":"computed AUC using sklearn.metrics.auc: -2.9635373077530076\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_TP9 = Xtrain['Theta_TP9']","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import auc\n\n\nxx = np.arange(0,525,1)\nyy = theta_TP9\n\nprint('computed AUC using sklearn.metrics.auc: {}'.format(auc(xx,yy)))\n","execution_count":72,"outputs":[{"output_type":"stream","text":"computed AUC using sklearn.metrics.auc: -67.27088557304509\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_TP10 = Xtrain['Theta_TP10']","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import auc\n\n\nxx = np.arange(0,525,1)\nyy = theta_TP9\n\nprint('computed AUC using sklearn.metrics.auc: {}'.format(auc(xx,yy)))\n","execution_count":74,"outputs":[{"output_type":"stream","text":"computed AUC using sklearn.metrics.auc: -67.27088557304509\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}